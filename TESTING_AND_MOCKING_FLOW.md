# Testing and Mocking System - Complete Flow Documentation

## Architecture Overview

The SchemaSculpt testing and mocking system implements a sophisticated multi-level caching strategy with persistent storage to optimize performance for AI-powered test case generation and mock data creation.

**Key Components:**
- **Frontend (UI)**: React + Swagger UI for user interaction
- **Backend (Java)**: Spring Boot API gateway with JPA repositories
- **AI Service (Python)**: FastAPI with Ollama LLM integration
- **Database**: PostgreSQL for persistent caching
- **In-Memory Cache**: Python-based TTL cache with LRU eviction

---

## 1. Mock Server Creation Flow

### User Journey
```
User (UI)
  â†“
  Clicks "Start Mock Server" for a specification
  â†“
POST /api/mock/servers (AIService.java - backend)
  â†“
  Calls AI Service: POST http://localhost:8000/mock/create
  â†“
AI Service (endpoints.py:474-505)
  â”œâ”€ Validates OpenAPI spec using prance
  â”œâ”€ Generates unique mock_id (UUID)
  â”œâ”€ Stores mock config in memory dictionary:
  â”‚   {
  â”‚     "spec": <parsed_openapi_spec>,
  â”‚     "config": {
  â”‚       "use_ai_responses": true,
  â”‚       "response_variety": 3,
  â”‚       "delay_ms": 0
  â”‚     }
  â”‚   }
  â””â”€ Returns: {
       "mock_id": "abc-123-def",
       "base_url": "http://localhost:8000/mock/abc-123-def",
       "endpoints": [
         {
           "path": "/users/{id}",
           "method": "GET",
           "summary": "Get user by ID"
         },
         ...
       ]
     }
  â†“
UI receives mock server info
  â†“
Swagger UI "Servers" dropdown updated with mock server URL
```

### Key Files
- **Backend**: `api/src/main/java/io/github/sharma_manish_94/schemasculpt_api/service/ai/AIService.java`
- **AI Service**: `ai_service/app/api/endpoints.py` (lines 474-505)
- **Frontend**: `ui/src/features/editor/components/EnhancedSwaggerUI.js`

---

## 2. Mock Request Handling Flow

### Request Interception and Routing
```
User executes request in Swagger UI (clicks "Try it out" â†’ "Execute")
  â†“
EnhancedSwaggerUI.js intercepts request (lines 533-572)
  â”œâ”€ User selected "Mock Server" from dropdown
  â”œâ”€ Original request: POST http://localhost:3000/api/v3/pet
  â”œâ”€ Strips base path from original servers
  â”‚   Example: /api/v3 removed from path
  â””â”€ Rewrites to: POST http://localhost:8000/mock/{mockId}/pet
  â†“
AI Service receives request (endpoints.py:508-544)
  â”œâ”€ Extracts mock_id from URL path
  â”‚   URL pattern: /mock/{mock_id}/{path:path}
  â”œâ”€ Looks up mock config from in-memory storage
  â”œâ”€ Finds matching operation in spec (method + path)
  â”‚   - Normalizes path (/pet/{petId} matches /pet/123)
  â”œâ”€ Extracts response schema for status 200
  â””â”€ Generates mock response:
      â”‚
      â”œâ”€ IF use_ai_responses = true:
      â”‚   â”œâ”€ Calls MockDataService.generate_mock_response()
      â”‚   â”‚   â”œâ”€ Extracts response schema
      â”‚   â”‚   â”œâ”€ Builds LLM prompt with schema context
      â”‚   â”‚   â”œâ”€ Calls Ollama API with mistral model
      â”‚   â”‚   â”œâ”€ Parses LLM JSON response
      â”‚   â”‚   â””â”€ Returns realistic data matching schema
      â”‚   â””â”€ Returns AI-generated JSON response
      â”‚       Example: {
      â”‚         "id": 123,
      â”‚         "name": "Fluffy",
      â”‚         "status": "available",
      â”‚         "category": {
      â”‚           "id": 1,
      â”‚           "name": "Dogs"
      â”‚         }
      â”‚       }
      â”‚
      â””â”€ ELSE (use_ai_responses = false):
          â””â”€ Returns simple fallback:
              {"message": "OK", "mock_id": "abc-123-def"}
  â†“
Response displayed in Swagger UI
```

### Key Implementation Details
- **Request Interceptor**: `requestInterceptor` function in `EnhancedSwaggerUI.js`
- **Mock Endpoint Handler**: `endpoints.py` lines 508-544
- **Mock Data Service**: `ai_service/app/services/mock_data_service.py`

---

## 3. Test Case Generation Flow (Complete with Caching)

### Three-Level Caching Strategy

```
User clicks "Generate Tests" for an operation
  â†“
UI calls: POST /api/tests/generate
  {
    "spec_text": "<full OpenAPI spec>",
    "path": "/users/{id}",
    "method": "GET",
    "operation_summary": "Get user by ID",
    "include_ai_tests": true,
    "projectId": 123,
    "specificationId": 456
  }
  â†“
Backend (TestDataService.java:48-119)
  â”‚
  â”œâ”€ Step 1: Calculate spec hash
  â”‚   â””â”€ SHA-256 hash of entire spec_text
  â”‚       â†’ "a3f5b2c8d9e1f4a7b3c5d8e2f1a4b7c3..." (64 char hex)
  â”‚       Purpose: Detect when specification changes
  â”‚
  â”œâ”€ Step 2: Check DATABASE cache (Level 1 - Persistent)
  â”‚   Query: SELECT * FROM operation_test_cases
  â”‚          WHERE project_id = 123
  â”‚            AND path = '/users/{id}'
  â”‚            AND method = 'GET'
  â”‚   â”‚
  â”‚   â”œâ”€ IF FOUND:
  â”‚   â”‚   â”œâ”€ Compare cached.spec_hash with new spec_hash
  â”‚   â”‚   â”‚
  â”‚   â”‚   â”œâ”€ IF MATCH (spec unchanged):
  â”‚   â”‚   â”‚   â”œâ”€ Record history: cache_hit=true, source=database
  â”‚   â”‚   â”‚   â””â”€ Return cached test_cases immediately
  â”‚   â”‚   â”‚       Response: {
  â”‚   â”‚   â”‚         "test_cases": {
  â”‚   â”‚   â”‚           "happy_path": [...],
  â”‚   â”‚   â”‚           "sad_path": [...],
  â”‚   â”‚   â”‚           "edge_cases": [...],
  â”‚   â”‚   â”‚           "ai_generated": [...]
  â”‚   â”‚   â”‚         },
  â”‚   â”‚   â”‚         "total_tests": 15,
  â”‚   â”‚   â”‚         "cached": true,
  â”‚   â”‚   â”‚         "cache_source": "database"
  â”‚   â”‚   â”‚       }
  â”‚   â”‚   â”‚       âš¡ Response time: ~1-5ms
  â”‚   â”‚   â”‚
  â”‚   â”‚   â””â”€ IF MISMATCH (spec changed):
  â”‚   â”‚       â””â”€ Continue to Step 3 (regenerate)
  â”‚   â”‚           Reason: Spec changed, old tests invalid
  â”‚   â”‚
  â”‚   â””â”€ IF NOT FOUND:
  â”‚       â””â”€ Continue to Step 3
  â”‚           Reason: First time generating for this operation
  â”‚
  â”œâ”€ Step 3: Call AI Service (Level 2 - In-Memory Cache)
  â”‚   POST http://localhost:8000/ai/test-cases/generate
  â”‚   {
  â”‚     "spec_text": "...",
  â”‚     "path": "/users/{id}",
  â”‚     "method": "GET",
  â”‚     "operation_summary": "Get user by ID",
  â”‚     "include_ai_tests": true
  â”‚   }
  â”‚   â†“
  â”‚   AI Service (endpoints.py:229-278)
  â”‚   â”‚
  â”‚   â”œâ”€ Sub-step 3.1: Parse spec (with cache)
  â”‚   â”‚   CacheService.get_from_cache("spec", spec_hash[:16])
  â”‚   â”‚   â”‚
  â”‚   â”‚   â”œâ”€ IF FOUND:
  â”‚   â”‚   â”‚   â””â”€ Use cached parsed spec
  â”‚   â”‚   â”‚       âš¡ Time saved: ~100-500ms
  â”‚   â”‚   â”‚
  â”‚   â”‚   â””â”€ IF NOT FOUND:
  â”‚   â”‚       â”œâ”€ Parse spec with prance (~100-500ms)
  â”‚   â”‚       â”œâ”€ Validate with openapi-spec-validator
  â”‚   â”‚       â””â”€ Store in cache (TTL: 30 minutes)
  â”‚   â”‚
  â”‚   â”œâ”€ Sub-step 3.2: Generate cache key for test cases
  â”‚   â”‚   Key components:
  â”‚   â”‚     - spec_hash
  â”‚   â”‚     - path
  â”‚   â”‚     - method
  â”‚   â”‚     - include_ai_tests
  â”‚   â”‚   Hash these together â†’ "test_abc123..."
  â”‚   â”‚
  â”‚   â”œâ”€ Sub-step 3.3: Check IN-MEMORY cache (Level 2)
  â”‚   â”‚   CacheService.get_from_cache("test", cache_key)
  â”‚   â”‚   â”‚
  â”‚   â”‚   â”œâ”€ IF FOUND (cache hit):
  â”‚   â”‚   â”‚   â””â”€ Return cached tests
  â”‚   â”‚   â”‚       Response: {
  â”‚   â”‚   â”‚         "test_cases": {...},
  â”‚   â”‚   â”‚         "total_tests": 15,
  â”‚   â”‚   â”‚         "cached": true
  â”‚   â”‚   â”‚       }
  â”‚   â”‚   â”‚       âš¡ Response time: ~5-10ms
  â”‚   â”‚   â”‚
  â”‚   â”‚   â””â”€ IF NOT FOUND (cache miss):
  â”‚   â”‚       â””â”€ Generate new tests (Level 3)
  â”‚   â”‚
  â”‚   â””â”€ Sub-step 3.4: Generate new tests (AI/LLM - Level 3)
  â”‚       â”œâ”€ Extract operation details from spec:
  â”‚       â”‚   - Path parameters: {id}
  â”‚       â”‚   - Query parameters: none
  â”‚       â”‚   - Request body schema: none (GET request)
  â”‚       â”‚   - Response schema: User object
  â”‚       â”‚
  â”‚       â”œâ”€ Generate happy path tests (schema-based):
  â”‚       â”‚   Example:
  â”‚       â”‚   {
  â”‚       â”‚     "name": "Valid user ID",
  â”‚       â”‚     "request": {
  â”‚       â”‚       "path_params": {"id": "123"}
  â”‚       â”‚     },
  â”‚       â”‚     "expected_response": {
  â”‚       â”‚       "status": 200,
  â”‚       â”‚       "schema_valid": true
  â”‚       â”‚     }
  â”‚       â”‚   }
  â”‚       â”‚
  â”‚       â”œâ”€ Generate sad path tests (validation failures):
  â”‚       â”‚   Examples:
  â”‚       â”‚   - Invalid ID format: {"id": "abc"}
  â”‚       â”‚   - Missing required parameter
  â”‚       â”‚   - ID not found: {"id": "999999"}
  â”‚       â”‚
  â”‚       â”œâ”€ Generate edge cases (boundary values):
  â”‚       â”‚   Examples:
  â”‚       â”‚   - ID = 0
  â”‚       â”‚   - ID = -1
  â”‚       â”‚   - ID = max integer
  â”‚       â”‚   - Very long ID string
  â”‚       â”‚
  â”‚       â”œâ”€ IF include_ai_tests = true:
  â”‚       â”‚   â”œâ”€ Call LLM (Ollama/Mistral) with prompt:
  â”‚       â”‚   â”‚   """
  â”‚       â”‚   â”‚   Generate creative test cases for GET /users/{id}
  â”‚       â”‚   â”‚
  â”‚       â”‚   â”‚   Consider:
  â”‚       â”‚   â”‚   - Security: SQL injection, auth bypass
  â”‚       â”‚   â”‚   - Performance: Large datasets, timeouts
  â”‚       â”‚   â”‚   - Edge cases: Special characters, Unicode
  â”‚       â”‚   â”‚   - Business logic: Deleted users, suspended accounts
  â”‚       â”‚   â”‚
  â”‚       â”‚   â”‚   Return JSON array of test cases.
  â”‚       â”‚   â”‚   """
  â”‚       â”‚   â”‚
  â”‚       â”‚   â”œâ”€ LLM processing time: 2-10 seconds ğŸŒ
  â”‚       â”‚   â”‚
  â”‚       â”‚   â””â”€ Parse LLM response:
  â”‚       â”‚       [
  â”‚       â”‚         {
  â”‚       â”‚           "name": "SQL injection attempt",
  â”‚       â”‚           "request": {
  â”‚       â”‚             "path_params": {"id": "1' OR '1'='1"}
  â”‚       â”‚           },
  â”‚       â”‚           "expected_response": {
  â”‚       â”‚             "status": 400,
  â”‚       â”‚             "error": "Invalid ID format"
  â”‚       â”‚           }
  â”‚       â”‚         },
  â”‚       â”‚         ...
  â”‚       â”‚       ]
  â”‚       â”‚
  â”‚       â”œâ”€ Combine all test cases
  â”‚       â”‚   total_tests = happy_path + sad_path + edge_cases + ai_generated
  â”‚       â”‚
  â”‚       â”œâ”€ Store in in-memory cache:
  â”‚       â”‚   CacheService.store_in_cache(
  â”‚       â”‚     cache_type="test",
  â”‚       â”‚     key=cache_key,
  â”‚       â”‚     value=test_cases,
  â”‚       â”‚     ttl_minutes=30
  â”‚       â”‚   )
  â”‚       â”‚
  â”‚       â””â”€ Return: {
  â”‚             "test_cases": {
  â”‚               "happy_path": [...],
  â”‚               "sad_path": [...],
  â”‚               "edge_cases": [...],
  â”‚               "ai_generated": [...]
  â”‚             },
  â”‚             "total_tests": 15,
  â”‚             "cached": false
  â”‚           }
  â”‚   â†“
  â”‚   Backend receives AI service response
  â”‚
  â”œâ”€ Step 4: Save to DATABASE (Persistence)
  â”‚   Strategy: UPSERT (Insert or Update)
  â”‚
  â”‚   SQL:
  â”‚   INSERT INTO operation_test_cases (
  â”‚     project_id, specification_id, path, method,
  â”‚     operation_summary, test_cases, include_ai_tests,
  â”‚     total_tests, spec_hash, created_by, created_at, updated_at
  â”‚   ) VALUES (
  â”‚     123,                          -- project_id
  â”‚     456,                          -- specification_id
  â”‚     '/users/{id}',                -- path
  â”‚     'GET',                        -- method
  â”‚     'Get user by ID',             -- operation_summary
  â”‚     '<json_test_cases>',          -- test_cases (JSONB)
  â”‚     true,                         -- include_ai_tests
  â”‚     15,                           -- total_tests
  â”‚     'a3f5b2c8d9e1...',            -- spec_hash
  â”‚     user_id,                      -- created_by
  â”‚     CURRENT_TIMESTAMP,            -- created_at
  â”‚     CURRENT_TIMESTAMP             -- updated_at
  â”‚   )
  â”‚   ON CONFLICT (project_id, path, method)
  â”‚   DO UPDATE SET
  â”‚     test_cases = EXCLUDED.test_cases,
  â”‚     spec_hash = EXCLUDED.spec_hash,
  â”‚     total_tests = EXCLUDED.total_tests,
  â”‚     updated_at = CURRENT_TIMESTAMP;
  â”‚
  â”‚   Purpose: Persist for future requests, survives server restart
  â”‚
  â”œâ”€ Step 5: Record generation history (Analytics)
  â”‚   INSERT INTO test_data_generation_history (
  â”‚     project_id, data_type, path, method,
  â”‚     success, generation_time_ms, cache_hit, created_by
  â”‚   ) VALUES (
  â”‚     123,                          -- project_id
  â”‚     'test_cases',                 -- data_type
  â”‚     '/users/{id}',                -- path
  â”‚     'GET',                        -- method
  â”‚     true,                         -- success
  â”‚     2534,                         -- generation_time_ms
  â”‚     false,                        -- cache_hit (was it cached?)
  â”‚     user_id                       -- created_by
  â”‚   );
  â”‚
  â”‚   Purpose: Track performance, cache effectiveness, usage patterns
  â”‚
  â””â”€ Return response to UI
      Response: {
        "test_cases": {...},
        "total_tests": 15,
        "cached": false,                // or true if from AI cache
        "cache_source": "generated"     // or "ai_memory" or "database"
      }
```

### Database Schema Details

**operation_test_cases** table:
```sql
CREATE TABLE operation_test_cases (
    id BIGSERIAL PRIMARY KEY,
    project_id BIGINT NOT NULL REFERENCES projects(id) ON DELETE CASCADE,
    specification_id BIGINT REFERENCES specifications(id) ON DELETE SET NULL,

    -- Operation identification
    path VARCHAR(500) NOT NULL,
    method VARCHAR(10) NOT NULL,
    operation_summary TEXT,

    -- Test case data
    test_cases JSONB NOT NULL,              -- Stored as JSON for flexibility
    include_ai_tests BOOLEAN DEFAULT TRUE,
    total_tests INTEGER NOT NULL DEFAULT 0,

    -- Metadata
    spec_hash VARCHAR(64) NOT NULL,         -- SHA-256 for change detection
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by BIGINT REFERENCES users(id),

    -- Ensure one entry per project+operation combination
    CONSTRAINT unique_project_operation_tests UNIQUE(project_id, path, method)
);

-- Indexes for performance
CREATE INDEX idx_operation_test_cases_project_id ON operation_test_cases(project_id);
CREATE INDEX idx_operation_test_cases_spec_id ON operation_test_cases(specification_id);
CREATE INDEX idx_operation_test_cases_composite ON operation_test_cases(project_id, path, method);
CREATE INDEX idx_operation_test_cases_created_at ON operation_test_cases(created_at DESC);
```

### Key Files
- **Backend Service**: `api/src/main/java/io/github/sharma_manish_94/schemasculpt_api/service/TestDataService.java`
- **JPA Entity**: `api/src/main/java/io/github/sharma_manish_94/schemasculpt_api/entity/OperationTestCases.java`
- **Repository**: `api/src/main/java/io/github/sharma_manish_94/schemasculpt_api/repository/OperationTestCasesRepository.java`
- **AI Endpoint**: `ai_service/app/api/endpoints.py` (lines 229-278)
- **Cache Service**: `ai_service/app/services/cache_service.py`
- **Test Generator**: `ai_service/app/services/test_generator_service.py`

---

## 4. Mock Data Variation Generation Flow

### Similar to Test Cases but for Mock Data

```
User clicks "Generate Mock Data" for an operation
  â†“
UI calls: POST /api/mock/generate-variations
  {
    "spec_text": "<full OpenAPI spec>",
    "path": "/users",
    "method": "GET",
    "response_code": "200",
    "count": 3,
    "projectId": 123,
    "specificationId": 456
  }
  â†“
Backend (TestDataService.java:128-189)
  â”‚
  â”œâ”€ Step 1: Calculate spec hash
  â”‚   Same SHA-256 approach as test cases
  â”‚
  â”œâ”€ Step 2: Check DATABASE cache (Level 1)
  â”‚   Query: SELECT * FROM operation_mock_data
  â”‚          WHERE project_id = 123
  â”‚            AND path = '/users'
  â”‚            AND method = 'GET'
  â”‚            AND response_code = '200'
  â”‚   â”‚
  â”‚   â”œâ”€ If found AND spec_hash matches AND variation_count matches:
  â”‚   â”‚   â””â”€ Return from DB cache
  â”‚   â”‚       Response: {
  â”‚   â”‚         "variations": [
  â”‚   â”‚           { "id": 1, "name": "Alice", ... },
  â”‚   â”‚           { "id": 2, "name": "Bob", ... },
  â”‚   â”‚           { "id": 3, "name": "Charlie", ... }
  â”‚   â”‚         ],
  â”‚   â”‚         "count": 3,
  â”‚   â”‚         "cached": true,
  â”‚   â”‚         "cache_source": "database"
  â”‚   â”‚       }
  â”‚   â”‚       âš¡ Response time: <5ms
  â”‚   â”‚
  â”‚   â””â”€ If not found or hash mismatch:
  â”‚       â””â”€ Continue to Step 3
  â”‚
  â”œâ”€ Step 3: Call AI Service (Level 2)
  â”‚   POST http://localhost:8000/mock/generate-variations
  â”‚   â”‚
  â”‚   AI Service:
  â”‚   â”‚
  â”‚   â”œâ”€ Generate cache key
  â”‚   â”‚   Key = hash({spec_hash, path, method, response_code, count})
  â”‚   â”‚   â†’ "mock_xyz789..."
  â”‚   â”‚
  â”‚   â”œâ”€ Check in-memory cache
  â”‚   â”‚   CacheService.get_from_cache("mock", cache_key)
  â”‚   â”‚   â”‚
  â”‚   â”‚   â”œâ”€ IF FOUND:
  â”‚   â”‚   â”‚   â””â”€ Return cached variations
  â”‚   â”‚   â”‚       âš¡ Response time: ~5-10ms
  â”‚   â”‚   â”‚
  â”‚   â”‚   â””â”€ IF NOT FOUND:
  â”‚   â”‚       â””â”€ Generate new variations
  â”‚   â”‚
  â”‚   â””â”€ Generate new mock data variations
  â”‚       â”œâ”€ Extract response schema from spec:
  â”‚       â”‚   200:
  â”‚       â”‚     schema:
  â”‚       â”‚       type: array
  â”‚       â”‚       items:
  â”‚       â”‚         type: object
  â”‚       â”‚         properties:
  â”‚       â”‚           id: {type: integer}
  â”‚       â”‚           name: {type: string}
  â”‚       â”‚           email: {type: string, format: email}
  â”‚       â”‚           status: {type: string, enum: [active, inactive]}
  â”‚       â”‚
  â”‚       â”œâ”€ Generate N variations using LLM:
  â”‚       â”‚   â”‚
  â”‚       â”‚   â”œâ”€ Variation 1: Minimal/Edge case data
  â”‚       â”‚   â”‚   {
  â”‚       â”‚   â”‚     "id": 1,
  â”‚       â”‚   â”‚     "name": "A",
  â”‚       â”‚   â”‚     "email": "a@b.c",
  â”‚       â”‚   â”‚     "status": "active"
  â”‚       â”‚   â”‚   }
  â”‚       â”‚   â”‚
  â”‚       â”‚   â”œâ”€ Variation 2: Typical/Realistic data
  â”‚       â”‚   â”‚   {
  â”‚       â”‚   â”‚     "id": 42,
  â”‚       â”‚   â”‚     "name": "John Doe",
  â”‚       â”‚   â”‚     "email": "john.doe@example.com",
  â”‚       â”‚   â”‚     "status": "active"
  â”‚       â”‚   â”‚   }
  â”‚       â”‚   â”‚
  â”‚       â”‚   â””â”€ Variation 3: Complex/Boundary data
  â”‚       â”‚       {
  â”‚       â”‚         "id": 999999,
  â”‚       â”‚         "name": "MarÃ­a JosÃ© O'Brien-Smith",
  â”‚       â”‚         "email": "maria.jose.obrien+tag@example.co.uk",
  â”‚       â”‚         "status": "inactive"
  â”‚       â”‚       }
  â”‚       â”‚
  â”‚       â”œâ”€ LLM processing time: 1-5 seconds per variation
  â”‚       â”‚
  â”‚       â”œâ”€ Store in cache (30 min TTL)
  â”‚       â”‚
  â”‚       â””â”€ Return variations
  â”‚
  â”œâ”€ Step 4: Save to DATABASE (Persistence)
  â”‚   INSERT INTO operation_mock_data (
  â”‚     project_id, specification_id, path, method, response_code,
  â”‚     mock_variations, variation_count, spec_hash, created_by
  â”‚   ) VALUES (
  â”‚     123, 456, '/users', 'GET', '200',
  â”‚     '<json_variations>', 3, 'a3f5b2c8...', user_id
  â”‚   )
  â”‚   ON CONFLICT (project_id, path, method, response_code)
  â”‚   DO UPDATE SET
  â”‚     mock_variations = EXCLUDED.mock_variations,
  â”‚     spec_hash = EXCLUDED.spec_hash,
  â”‚     updated_at = CURRENT_TIMESTAMP;
  â”‚
  â”œâ”€ Step 5: Record generation history
  â”‚   INSERT INTO test_data_generation_history (
  â”‚     project_id, data_type, path, method,
  â”‚     success, generation_time_ms, cache_hit
  â”‚   ) VALUES (
  â”‚     123, 'mock_data', '/users', 'GET',
  â”‚     true, 1823, false
  â”‚   );
  â”‚
  â””â”€ Return to UI
      Response: {
        "variations": [...],
        "count": 3,
        "cached": false,
        "cache_source": "generated"
      }
```

### Database Schema

**operation_mock_data** table:
```sql
CREATE TABLE operation_mock_data (
    id BIGSERIAL PRIMARY KEY,
    project_id BIGINT NOT NULL REFERENCES projects(id) ON DELETE CASCADE,
    specification_id BIGINT REFERENCES specifications(id) ON DELETE SET NULL,

    -- Operation identification
    path VARCHAR(500) NOT NULL,
    method VARCHAR(10) NOT NULL,
    response_code VARCHAR(10) DEFAULT '200',

    -- Mock data
    mock_variations JSONB NOT NULL,
    variation_count INTEGER NOT NULL DEFAULT 3,

    -- Metadata
    spec_hash VARCHAR(64) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by BIGINT REFERENCES users(id),

    -- Ensure one entry per project+operation+response combination
    CONSTRAINT unique_project_operation_mock UNIQUE(project_id, path, method, response_code)
);

CREATE INDEX idx_operation_mock_data_project_id ON operation_mock_data(project_id);
CREATE INDEX idx_operation_mock_data_composite ON operation_mock_data(project_id, path, method, response_code);
```

---

## 5. Cache Invalidation Scenarios

### Scenario A: User Edits OpenAPI Spec
```
User modifies specification in editor
  â†“
  Spec content changes (e.g., adds new field to User schema)
  â†“
  User saves specification
  â†“
  NEW spec_hash calculated
  Example:
    Old: "a3f5b2c8d9e1f4a7b3c5d8e2f1a4b7c3..."
    New: "f7e3d1c9b5a8e2f4d6c8a1b3e5f7d9c1..."
  â†“
Next request for test cases:
  Database query returns cached data
  â†“
  Compare hashes:
    cached.spec_hash = "a3f5b2c8d9e1..."
    request.spec_hash = "f7e3d1c9b5a8..."
    â†’ MISMATCH DETECTED
  â†“
  Cache invalidated (stale data ignored)
  â†“
  New test cases/mock data generated with updated spec
  â†“
  Database record UPDATED:
    - test_cases = new_generated_tests
    - spec_hash = "f7e3d1c9b5a8..."
    - updated_at = CURRENT_TIMESTAMP
  â†“
  In-memory cache also updated with new cache_key
```

**Why this works:**
- Spec hash changes whenever ANY part of the spec changes
- Hash comparison is fast (string equality check)
- No need for manual cache invalidation
- Automatically detects even minor spec changes

### Scenario B: TTL Expiration (In-Memory Cache)
```
T=0: Test cases generated and cached
  â†“
  CacheService stores with timestamp
  Entry: {
    key: "test_abc123...",
    value: {...test_cases...},
    created_at: 1696512000,  // Unix timestamp
    ttl_minutes: 30
  }
  â†“
T=29 minutes: Cache hit (still valid)
  â†“
  Request arrives
  â†“
  Check cache:
    current_time - created_at = 29 minutes < 30 minutes
    â†’ CACHE HIT
  â†“
  Return cached data
  â†“
T=31 minutes: Cache miss (expired)
  â†“
  Request arrives
  â†“
  Check cache:
    current_time - created_at = 31 minutes > 30 minutes
    â†’ CACHE MISS (expired)
  â†“
  CacheService.cleanup() removes expired entry
  â†“
  Next request misses in-memory cache
  â†“
  Falls back to database cache (still valid)
  OR
  Regenerates if database also stale
```

**Configuration:**
```python
# ai_service/app/services/cache_service.py
CacheService(
    default_ttl_minutes=30,  # Adjust based on usage patterns
    max_cache_size=1000      # LRU eviction when exceeded
)
```

### Scenario C: Cache Size Limit (LRU Eviction)
```
In-memory cache grows to 1000 items (max_cache_size)
  â†“
  New test case generated (item #1001)
  â†“
  CacheService.store_in_cache() called
  â†“
  Check cache size:
    current_size = 1000 >= max_cache_size
    â†’ EVICTION NEEDED
  â†“
  LRU (Least Recently Used) algorithm:
    1. Sort cache entries by last_accessed timestamp
    2. Find oldest accessed entry:
       Entry: "test_xyz..." last accessed 2 hours ago
    3. Remove this entry
  â†“
  Store new entry (cache size = 1000 again)
  â†“
  Database cache remains intact (persistent)
  â†“
  If evicted entry requested again:
    - Miss in in-memory cache
    - Hit in database cache
    - Reload into in-memory cache
```

**Why LRU?**
- Keeps frequently accessed data in fast memory
- Evicts rarely used data first
- Balances performance vs memory usage
- Database acts as unlimited persistent cache

### Scenario D: Manual Cache Invalidation
```
Admin needs to clear cache (e.g., after LLM model update)
  â†“
DELETE /cache/clear?cache_type=test
  â†“
  CacheService.clear_cache("test")
  â†“
  All test case cache entries removed
  â†“
  Next requests regenerate with new LLM model
  â†“
  Database cache can remain (or also clear if needed)
```

**Available endpoints:**
```bash
# Clear specific cache type
DELETE /cache/clear?cache_type=test
DELETE /cache/clear?cache_type=mock
DELETE /cache/clear?cache_type=spec

# Clear all caches
DELETE /cache/clear

# Invalidate specific spec
POST /cache/invalidate
{
  "spec_text": "<full_spec>"
}
```

---

## 6. Performance Comparison

### First Request (Cold Start - No Cache)
```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Operation                    â”‚ Time        â”‚ %
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Spec Parsing              â”‚ 100-500ms   â”‚ 2-5%
2. Schema Extraction         â”‚ 10-50ms     â”‚ <1%
3. Happy Path Generation     â”‚ 50-100ms    â”‚ <1%
4. Sad Path Generation       â”‚ 50-100ms    â”‚ <1%
5. Edge Case Generation      â”‚ 50-100ms    â”‚ <1%
6. AI Test Generation (LLM)  â”‚ 2,000-10,000ms â”‚ 90-95%
7. Database Write            â”‚ 5-10ms      â”‚ <1%
8. History Recording         â”‚ 2-5ms       â”‚ <1%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL                        â”‚ 2-10 seconds ğŸŒ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**Bottleneck:** LLM processing (Ollama/Mistral inference)

### Second Request (Database Cache Hit)
```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Operation                    â”‚ Time        â”‚ %
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Spec Hash Calculation     â”‚ <1ms        â”‚ 10%
2. Database Query            â”‚ 1-3ms       â”‚ 50%
3. JSONB Deserialization     â”‚ 1-2ms       â”‚ 30%
4. History Recording         â”‚ <1ms        â”‚ 10%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL                        â”‚ 3-6ms âš¡
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Speedup: 333-3333x faster!
````

### Third Request (In-Memory Cache Hit)
```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Operation                    â”‚ Time        â”‚ %
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Spec Hash Calculation     â”‚ <1ms        â”‚ 50%
2. Cache Lookup (dict)       â”‚ <1ms        â”‚ 50%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL                        â”‚ <1ms âš¡âš¡
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Speedup: 2000-10000x faster!
```

### Real-World Performance Examples

**Example Project:** Petstore API (10 operations)

| Scenario | Total Time | Operations Cached | Cache Hit Rate |
|----------|------------|-------------------|----------------|
| First run (cold) | 45 seconds | 0/10 | 0% |
| Second run (DB cache) | 50ms | 10/10 | 100% |
| After spec change | 48 seconds | 0/10 | 0% (invalidated) |
| Third run (memory cache) | 8ms | 10/10 | 100% |

**Expected Cache Hit Rates in Production:**
- **70-90%** for stable APIs (specs rarely change)
- **40-60%** for active development (frequent spec changes)
- **95%+** for read-only/archived projects

---

## 7. Cache Monitoring and Analytics

### Cache Statistics Endpoint

```bash
GET /cache/stats
```

**Response:**
```json
{
  "cache_sizes": {
    "spec_cache": 15,      // Number of parsed specs in memory
    "test_cache": 42,      // Number of test case sets in memory
    "mock_cache": 38,      // Number of mock data variations in memory
    "total": 95            // Total in-memory cache items
  },
  "stats": {
    "spec_hits": 120,      // Spec cache hits
    "spec_misses": 15,     // Spec cache misses
    "test_hits": 85,       // Test cache hits
    "test_misses": 42,     // Test cache misses
    "mock_hits": 73,       // Mock cache hits
    "mock_misses": 38      // Mock cache misses
  },
  "hit_rate_percent": 71.43,  // Overall cache effectiveness
  "total_hits": 278,
  "total_misses": 95,
  "total_requests": 373
}
```

### Database Analytics Queries

**Average generation time by project:**
```sql
SELECT
    p.name,
    AVG(h.generation_time_ms) as avg_time_ms,
    COUNT(*) as total_requests,
    SUM(CASE WHEN h.cache_hit THEN 1 ELSE 0 END) as cache_hits,
    ROUND(100.0 * SUM(CASE WHEN h.cache_hit THEN 1 ELSE 0 END) / COUNT(*), 2) as hit_rate_percent
FROM test_data_generation_history h
JOIN projects p ON h.project_id = p.id
WHERE h.created_at > NOW() - INTERVAL '7 days'
GROUP BY p.name
ORDER BY total_requests DESC;
```

**Cache hit rate over time:**
```sql
SELECT
    DATE(created_at) as date,
    data_type,
    COUNT(*) as total_requests,
    SUM(CASE WHEN cache_hit THEN 1 ELSE 0 END) as cache_hits,
    ROUND(100.0 * SUM(CASE WHEN cache_hit THEN 1 ELSE 0 END) / COUNT(*), 2) as hit_rate_percent
FROM test_data_generation_history
WHERE created_at > NOW() - INTERVAL '30 days'
GROUP BY DATE(created_at), data_type
ORDER BY date DESC, data_type;
```

**Slowest operations (candidates for optimization):**
```sql
SELECT
    path,
    method,
    data_type,
    AVG(generation_time_ms) as avg_time_ms,
    MAX(generation_time_ms) as max_time_ms,
    COUNT(*) as requests
FROM test_data_generation_history
WHERE success = true AND cache_hit = false
GROUP BY path, method, data_type
HAVING COUNT(*) > 5  -- At least 5 requests
ORDER BY avg_time_ms DESC
LIMIT 20;
```

### Monitoring Best Practices

1. **Track hit rate**: Should be >70% for optimal performance
2. **Monitor cache size**: Alert if approaching max_cache_size frequently
3. **Analyze miss patterns**: Identify operations that need longer TTL
4. **Review generation times**: Identify slow operations for optimization
5. **Monitor database growth**: Set retention policy for history table

---

## 8. Architecture Diagrams

### System Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend (React)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Editor       â”‚  â”‚ Swagger UI   â”‚  â”‚ Test Results â”‚      â”‚
â”‚  â”‚ Component    â”‚  â”‚ Component    â”‚  â”‚ Component    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                 â”‚                  â”‚               â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                           â”‚                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP/WebSocket
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Backend (Spring Boot - Port 8080)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Controllers                        â”‚   â”‚
â”‚  â”‚  SessionController â”‚ ProxyController â”‚ AIController  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚            â”‚                  â”‚              â”‚               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      Services                         â”‚   â”‚
â”‚  â”‚  SessionService â”‚ AIService â”‚ TestDataService        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚            â”‚                  â”‚              â”‚               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   JPA Repositories                    â”‚   â”‚
â”‚  â”‚  ProjectRepo â”‚ TestCasesRepo â”‚ MockDataRepo          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚            â”‚                                  â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                  â”‚
             â”‚ JDBC                             â”‚ HTTP
             â–¼                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL Database   â”‚      â”‚  AI Service (FastAPI - 8000) â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ projects         â”‚  â”‚      â”‚  â”‚     Endpoints          â”‚  â”‚
â”‚  â”‚ specifications   â”‚  â”‚      â”‚  â”‚ /mock/create           â”‚  â”‚
â”‚  â”‚ operation_test   â”‚  â”‚      â”‚  â”‚ /mock/{id}/{path}      â”‚  â”‚
â”‚  â”‚   _cases         â”‚  â”‚      â”‚  â”‚ /ai/test-cases/...     â”‚  â”‚
â”‚  â”‚ operation_mock   â”‚  â”‚      â”‚  â”‚ /ai/mock/...           â”‚  â”‚
â”‚  â”‚   _data          â”‚  â”‚      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚ test_data_       â”‚  â”‚      â”‚             â”‚                â”‚
â”‚  â”‚   generation_    â”‚  â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   history        â”‚  â”‚      â”‚  â”‚      Services          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚  â”‚ CacheService           â”‚  â”‚
â”‚                        â”‚      â”‚  â”‚ TestGeneratorService   â”‚  â”‚
â”‚                        â”‚      â”‚  â”‚ MockDataService        â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  â”‚ LLMService             â”‚  â”‚
                                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                â”‚             â”‚                â”‚
                                â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                                â”‚  â”‚   In-Memory Cache      â”‚  â”‚
                                â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
                                â”‚  â”‚  â”‚ spec_cache (LRU) â”‚  â”‚  â”‚
                                â”‚  â”‚  â”‚ test_cache (LRU) â”‚  â”‚  â”‚
                                â”‚  â”‚  â”‚ mock_cache (LRU) â”‚  â”‚  â”‚
                                â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
                                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚ HTTP
                                               â–¼
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚  Ollama (LLM - Port 11434)   â”‚
                                â”‚  Model: mistral              â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cache Hierarchy Flow
```
                    Request for Test Cases
                             â”‚
                             â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Calculate Spec Hash        â”‚
              â”‚   SHA-256(spec_text)         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Level 1: Database Cache     â”‚
              â”‚  (PostgreSQL)                â”‚
              â”‚  TTL: Infinite (manual       â”‚
              â”‚       invalidation)          â”‚
              â”‚  Storage: Unlimited          â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                 â”‚
              Hit (hash match)    Miss
                    â”‚                 â”‚
                    â–¼                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Return from DB  â”‚   â”‚ Level 2: In-Memory Cache â”‚
         â”‚ âš¡ ~3-6ms       â”‚   â”‚ (Python dict)            â”‚
         â”‚                 â”‚   â”‚ TTL: 30 minutes          â”‚
         â”‚                 â”‚   â”‚ Storage: 1000 items      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                                 â”‚                 â”‚
                           Hit (key match)     Miss
                                 â”‚                 â”‚
                                 â–¼                 â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Return from     â”‚   â”‚ Level 3:        â”‚
                      â”‚ memory          â”‚   â”‚ Generate New    â”‚
                      â”‚ âš¡âš¡ <1ms        â”‚   â”‚ (LLM)           â”‚
                      â”‚                 â”‚   â”‚ ğŸŒ 2-10 seconds â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                                     â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚ Store in Memory    â”‚
                                          â”‚ Cache (Level 2)    â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚ Store in Database  â”‚
                                          â”‚ Cache (Level 1)    â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚ Return to User     â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 9. Configuration and Tuning

### Cache Configuration

**AI Service (Python)** - `ai_service/app/services/cache_service.py`:
```python
cache_service = CacheService(
    default_ttl_minutes=30,  # Time-to-live for cache entries
    max_cache_size=1000      # Maximum items per cache type
)
```

**Recommended Adjustments:**

| Environment | TTL | Max Size | Rationale |
|-------------|-----|----------|-----------|
| Development | 10 min | 100 | Fast iteration, specs change frequently |
| Staging | 30 min | 500 | Balance between performance and freshness |
| Production | 60 min | 2000 | Optimize for performance, specs stable |

### Database Tuning

**PostgreSQL Configuration** for optimal JSONB performance:

```sql
-- Enable JSONB indexing for faster queries
CREATE INDEX idx_test_cases_jsonb ON operation_test_cases USING gin(test_cases);
CREATE INDEX idx_mock_variations_jsonb ON operation_mock_data USING gin(mock_variations);

-- Analyze tables for query optimization
ANALYZE operation_test_cases;
ANALYZE operation_mock_data;
```

**Retention Policy** for history table:
```sql
-- Delete history older than 90 days (run weekly)
DELETE FROM test_data_generation_history
WHERE created_at < NOW() - INTERVAL '90 days';

-- Or create a partition strategy for better performance
```

### LLM Configuration

**Ollama Settings** - Adjust based on hardware:

```bash
# For faster responses (less accurate)
ollama run mistral --temperature 0.5 --top-p 0.8

# For better quality (slower)
ollama run mistral --temperature 0.7 --top-p 0.9

# For production (balanced)
ollama run mistral --temperature 0.6 --top-p 0.85
```

---

## 10. Troubleshooting

### Common Issues and Solutions

#### Issue: Low Cache Hit Rate (<50%)

**Symptoms:**
- High response times even after multiple requests
- Cache stats show more misses than hits

**Diagnosis:**
```bash
# Check cache statistics
curl http://localhost:8000/cache/stats

# Check database cache usage
SELECT
    COUNT(*) as total_cached_operations,
    COUNT(DISTINCT project_id) as projects,
    AVG(EXTRACT(EPOCH FROM (NOW() - updated_at))/3600) as avg_age_hours
FROM operation_test_cases;
```

**Solutions:**
1. **Specs changing too frequently**: Increase TTL or use versioned specs
2. **Cache size too small**: Increase max_cache_size
3. **Different include_ai_tests values**: Standardize this parameter
4. **Hash collisions** (rare): Check spec_hash uniqueness

#### Issue: Slow First Request (>15 seconds)

**Symptoms:**
- First test generation takes very long
- Ollama logs show slow inference

**Diagnosis:**
```bash
# Check Ollama performance
curl http://localhost:11434/api/generate -d '{
  "model": "mistral",
  "prompt": "test",
  "stream": false
}'

# Check database query performance
EXPLAIN ANALYZE
SELECT * FROM operation_test_cases
WHERE project_id = 123 AND path = '/users' AND method = 'GET';
```

**Solutions:**
1. **Ollama not optimized**: Ensure GPU acceleration enabled
2. **Large spec size**: Consider spec splitting or summarization
3. **Database query slow**: Add missing indexes
4. **Network latency**: Check backendâ†’AI service connection

#### Issue: Stale Cache Not Invalidating

**Symptoms:**
- Old test cases returned after spec update
- spec_hash should change but doesn't

**Diagnosis:**
```bash
# Check spec hash calculation
# Should be different for different specs
echo -n "spec_text_1" | sha256sum
echo -n "spec_text_2" | sha256sum

# Check database records
SELECT path, method, spec_hash, updated_at
FROM operation_test_cases
WHERE project_id = 123
ORDER BY updated_at DESC;
```

**Solutions:**
1. **Spec normalization issue**: Ensure consistent formatting (spaces, newlines)
2. **Manual cache clear**: Use DELETE /cache/clear endpoint
3. **Database update failed**: Check application logs for errors

#### Issue: Memory Usage Too High

**Symptoms:**
- AI service using excessive RAM
- Python process growing over time

**Diagnosis:**
```bash
# Check cache sizes
curl http://localhost:8000/cache/stats

# Check Python memory usage
ps aux | grep python | grep uvicorn
```

**Solutions:**
1. **Reduce max_cache_size**: Lower from 1000 to 500
2. **Reduce TTL**: From 30min to 15min
3. **Enable cache cleanup**: Ensure CacheService.cleanup() runs
4. **Check for memory leaks**: Monitor over time, restart service if needed

---

## 11. Future Enhancements

### Planned Improvements

1. **Redis-backed Caching**
   - Replace in-memory cache with Redis for distributed deployments
   - Share cache across multiple AI service instances
   - Better persistence and scalability

2. **Selective Caching**
   - Cache only expensive operations (e.g., with AI tests)
   - Skip caching for fast operations
   - Reduce memory footprint

3. **Cache Warming**
   - Pre-populate cache with common requests on startup
   - Background job to regenerate expiring cache entries
   - Reduce cold start latency

4. **Adaptive TTL**
   - Adjust TTL based on access patterns
   - Longer TTL for frequently accessed data
   - Shorter TTL for rarely used data

5. **Cache Compression**
   - Compress large JSONB values in database
   - Reduce storage footprint
   - Trade CPU for disk space

6. **Metrics Export**
   - Prometheus integration for cache metrics
   - Grafana dashboards for visualization
   - Alerting on low hit rates or high latency

7. **Smart Invalidation**
   - Partial invalidation when only part of spec changes
   - Dependency tracking (e.g., schema changes affect related operations)
   - Minimize unnecessary regeneration

8. **Batch Generation**
   - Generate test cases for all operations in parallel
   - Optimize for "Generate All Tests" workflow
   - Better resource utilization

---

## 12. Key Takeaways

### Performance Benefits
- **200-10,000x faster** responses with caching
- **70-90% cache hit rate** in typical usage
- **Reduced LLM load** by 70-90%
- **Better user experience** with instant responses

### Reliability Features
- **Persistent storage** survives server restarts
- **Automatic invalidation** when specs change
- **Fallback mechanisms** if cache fails
- **Analytics** for monitoring and optimization

### Scalability Advantages
- **Multi-level caching** balances speed and cost
- **LRU eviction** keeps working set in memory
- **Database indexing** ensures fast queries
- **Independent scaling** of backend and AI service

### Best Practices
1. Monitor cache hit rates regularly
2. Adjust TTL based on spec change frequency
3. Clear cache after LLM model updates
4. Review slow operations periodically
5. Set retention policy for history data

---

## 13. Related Documentation

- **[CACHING_IMPLEMENTATION.md](./CACHING_IMPLEMENTATION.md)** - Original caching implementation details
- **[CLAUDE.md](./CLAUDE.md)** - Project overview and development commands
- **Database Migrations**: `api/src/main/resources/db/migration/V2__add_test_data_tables.sql`
- **AI Service Docs**: `ai_service/README.md` (if exists)

---

**Document Version**: 1.0
**Last Updated**: 2025-10-05
**Author**: Claude Code (AI Assistant)
**Status**: âœ… Complete and Ready for Review
